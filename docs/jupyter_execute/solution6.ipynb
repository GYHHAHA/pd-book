{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "817663d8",
   "metadata": {
    "tags": [
     "remove_input"
    ]
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "np.random.seed(0)\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei']\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "np.set_printoptions(suppress = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00f3c10d",
   "metadata": {},
   "source": [
    "# 第六章\n",
    "\n",
    "## 零、练一练\n",
    "\n",
    "```{admonition} 练一练\n",
    "请写出以下集合A和集合B的笛卡尔积：\n",
    "- $A=\\{0\\}$；$B=\\{0\\}$\n",
    "- $A=\\{1, 2, 3\\}$；$B=\\{4, 5, 6\\}$ \n",
    "- $A=\\{\\{1,2\\}, 3\\}$；$B=\\{4,\\{5,6\\}\\}$\n",
    "```\n",
    "\n",
    "- $\\{(0, 0)\\}$\n",
    "- $\\{(1,4),(1,5),(1,6),(2,4),(2,5),(2,6),(3,4),(3,5),(3,6)\\}$\n",
    "- $\\{(\\{1,2\\},4),(\\{1,2\\},\\{5,6\\}),(3,4),(3,\\{5,6\\})\\}$\n",
    "\n",
    "```{admonition} 练一练\n",
    "假设左表键的所在列元素列表为[1,2,2,3,3,3]，右表键与左表相同，请问用4种方式连接得到的结果表分别具有多少行？\n",
    "```\n",
    "\n",
    "4种连接方式都是$1^2+2^2+3^2=14$行\n",
    "\n",
    "```{admonition} 练一练\n",
    "请构造两张表使它们在用merge()合并时能够通过“1:m”的检查但无法通过“m:1”模式的检查。\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c933d284",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_left = pd.DataFrame({\"A\":[1,2], \"B\":[\"a\",\"b\"]})\n",
    "df_right = pd.DataFrame({\"A\":[1,1,2], \"C\":[\"c\",\"d\",\"e\"]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9c174d56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>a</td>\n",
       "      <td>c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>a</td>\n",
       "      <td>d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>b</td>\n",
       "      <td>e</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   A  B  C\n",
       "0  1  a  c\n",
       "1  1  a  d\n",
       "2  2  b  e"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_left.merge(df_right, on=\"A\", validate=\"1:m\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3da8c0ee",
   "metadata": {
    "tags": [
     "raises-exception"
    ]
   },
   "outputs": [
    {
     "ename": "MergeError",
     "evalue": "Merge keys are not unique in right dataset; not a many-to-one merge",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMergeError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [4]\u001b[0m, in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mdf_left\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmerge\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_right\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mA\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mm:1\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\final\\lib\\site-packages\\pandas\\core\\frame.py:9329\u001b[0m, in \u001b[0;36mDataFrame.merge\u001b[1;34m(self, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[0;32m   9310\u001b[0m \u001b[38;5;129m@Substitution\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   9311\u001b[0m \u001b[38;5;129m@Appender\u001b[39m(_merge_doc, indents\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m   9312\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmerge\u001b[39m(\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   9325\u001b[0m     validate: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   9326\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame:\n\u001b[0;32m   9327\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mreshape\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmerge\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m merge\n\u001b[1;32m-> 9329\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmerge\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   9330\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   9331\u001b[0m \u001b[43m        \u001b[49m\u001b[43mright\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   9332\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhow\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   9333\u001b[0m \u001b[43m        \u001b[49m\u001b[43mon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mon\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   9334\u001b[0m \u001b[43m        \u001b[49m\u001b[43mleft_on\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mleft_on\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   9335\u001b[0m \u001b[43m        \u001b[49m\u001b[43mright_on\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mright_on\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   9336\u001b[0m \u001b[43m        \u001b[49m\u001b[43mleft_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mleft_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   9337\u001b[0m \u001b[43m        \u001b[49m\u001b[43mright_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mright_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   9338\u001b[0m \u001b[43m        \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   9339\u001b[0m \u001b[43m        \u001b[49m\u001b[43msuffixes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msuffixes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   9340\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   9341\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindicator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindicator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   9342\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   9343\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\final\\lib\\site-packages\\pandas\\core\\reshape\\merge.py:107\u001b[0m, in \u001b[0;36mmerge\u001b[1;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[0;32m     90\u001b[0m \u001b[38;5;129m@Substitution\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mleft : DataFrame or named Series\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     91\u001b[0m \u001b[38;5;129m@Appender\u001b[39m(_merge_doc, indents\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     92\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmerge\u001b[39m(\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    105\u001b[0m     validate: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    106\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame:\n\u001b[1;32m--> 107\u001b[0m     op \u001b[38;5;241m=\u001b[39m \u001b[43m_MergeOperation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    108\u001b[0m \u001b[43m        \u001b[49m\u001b[43mleft\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    109\u001b[0m \u001b[43m        \u001b[49m\u001b[43mright\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    110\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhow\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    111\u001b[0m \u001b[43m        \u001b[49m\u001b[43mon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mon\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    112\u001b[0m \u001b[43m        \u001b[49m\u001b[43mleft_on\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mleft_on\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    113\u001b[0m \u001b[43m        \u001b[49m\u001b[43mright_on\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mright_on\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    114\u001b[0m \u001b[43m        \u001b[49m\u001b[43mleft_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mleft_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    115\u001b[0m \u001b[43m        \u001b[49m\u001b[43mright_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mright_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    116\u001b[0m \u001b[43m        \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    117\u001b[0m \u001b[43m        \u001b[49m\u001b[43msuffixes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msuffixes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    118\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    119\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindicator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindicator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    120\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    121\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    122\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m op\u001b[38;5;241m.\u001b[39mget_result()\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\final\\lib\\site-packages\\pandas\\core\\reshape\\merge.py:710\u001b[0m, in \u001b[0;36m_MergeOperation.__init__\u001b[1;34m(self, left, right, how, on, left_on, right_on, axis, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[0;32m    706\u001b[0m \u001b[38;5;66;03m# If argument passed to validate,\u001b[39;00m\n\u001b[0;32m    707\u001b[0m \u001b[38;5;66;03m# check if columns specified as unique\u001b[39;00m\n\u001b[0;32m    708\u001b[0m \u001b[38;5;66;03m# are in fact unique.\u001b[39;00m\n\u001b[0;32m    709\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m validate \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 710\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalidate\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\final\\lib\\site-packages\\pandas\\core\\reshape\\merge.py:1444\u001b[0m, in \u001b[0;36m_MergeOperation._validate\u001b[1;34m(self, validate)\u001b[0m\n\u001b[0;32m   1442\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m validate \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmany_to_one\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mm:1\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m   1443\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m right_unique:\n\u001b[1;32m-> 1444\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m MergeError(\n\u001b[0;32m   1445\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMerge keys are not unique in right dataset; \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1446\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnot a many-to-one merge\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1447\u001b[0m         )\n\u001b[0;32m   1449\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m validate \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmany_to_many\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mm:m\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m   1450\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "\u001b[1;31mMergeError\u001b[0m: Merge keys are not unique in right dataset; not a many-to-one merge"
     ]
    }
   ],
   "source": [
    "df_left.merge(df_right, on=\"A\", validate=\"m:1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ce7ed43",
   "metadata": {},
   "source": [
    "```{admonition} 练一练\n",
    "join()函数没有实现merge()函数中的validate参数，请构造1个join_with_validate函数，其参数包含df1、df2、on、how和validate，完成与merge()类似的功能。（允许在join_with_validate内部调用join()函数）\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8228a07c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# is_unique未在教材中提到，读者可以使用集合去重再判断元素数量的方法\n",
    "def join_with_validate(df1, df2, on, how=\"left\", validate=\"m:m\"):\n",
    "    df1_index_not_unique = not df1.index.is_unique\n",
    "    df2_index_not_unique = not df2.index.is_unique\n",
    "    if validate==\"1:1\" and (df1_index_not_unique or df2_index_not_unique):\n",
    "        raise ValueError(\n",
    "            \"Join keys are not unique in dataset; \"\n",
    "            \"not a one-to-one merge\"\n",
    "        )\n",
    "    if validate==\"1:m\" and df1_index_not_unique:\n",
    "        raise ValueError(\n",
    "            \"Join keys are not unique in left dataset; \"\n",
    "            \"not a one-to-many merge\"\n",
    "        )\n",
    "    if validate==\"m:1\" and df2_index_not_unique:\n",
    "        raise ValueError(\n",
    "            \"Join keys are not unique in right dataset; \"\n",
    "            \"not a many-to-one merge\"\n",
    "        )\n",
    "    return df1.join(df2, on=on, how=how)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e9cef9",
   "metadata": {},
   "source": [
    "```{admonition} 练一练\n",
    "给定两个具有相同行列索引的DataFrame，设s1和s2分别是传入规则函数的左表列和右表列，请依次根据如下规则更新进行组合：\n",
    "- 当s1中的元素值为0时，使用s2对应位置元素更新，否则保持不变。\n",
    "- 当s1中的元素值超过s2的均值时，使用s1+s2的对应位置元素更新，否则使用s1-s2的对应位置元素更新。\n",
    "```\n",
    "\n",
    "- 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a7327c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame({\"A\":[0,2],\"B\":[4,1]})\n",
    "df2 = pd.DataFrame({\"A\":[1,0],\"B\":[3,-1]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e1c152c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   A  B\n",
       "0  1  4\n",
       "1  2  1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.combine(df2, lambda s1, s2: s1.mask(s1==0, s2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5a572bb",
   "metadata": {},
   "source": [
    "- 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5aa2e496",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   A  B\n",
       "0 -1  7\n",
       "1  2  2"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.combine(df2, lambda s1, s2: (s1-s2).mask(s1>s2.mean(), s1+s2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf46dda2",
   "metadata": {},
   "source": [
    "## 一、合并员工信息表\n",
    "\n",
    "在data/ch6/employee文件夹下，存放了某公司的员工信息。其中，salary目录下存放了从2018年1月至2020年12月时间段内，每月员工的基本工资数额，award目录下存放了每月员工的奖金数额，员工最终的工资等于基本工资加上奖金。（注：本题中数据均为随机生成，与现实无关）\n",
    "\n",
    "- info_a.csv、info_b.csv和info_c.csv中分别存放了公司员工的不同信息，请提取ID从“ID-000001”至“ID-025000”对应员工的邮箱、性别、年龄和学历，并将它们合并成一张表，索引为员工ID。\n",
    "- 对所有ID在上题范围内的员工统计从18年1月至20年12月每个季度的工资总数，并将这12个季度的结果作为新的列添加至上一问的结果表中。统计2018年第1季度的结果时，列名即为“2018-Q1”，其他季度对应列的名字以此类推。\n",
    "\n",
    "```text\n",
    "【解答】\n",
    "```\n",
    "\n",
    "- 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5c5f6451",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>邮箱</th>\n",
       "      <th>性别</th>\n",
       "      <th>年龄</th>\n",
       "      <th>学历</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ID-000001</th>\n",
       "      <td>oZuSkKV@qq.com</td>\n",
       "      <td>男</td>\n",
       "      <td>38.0</td>\n",
       "      <td>研究生</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID-000002</th>\n",
       "      <td>IWmJnPR@yahoo.com</td>\n",
       "      <td>女</td>\n",
       "      <td>37.0</td>\n",
       "      <td>高中</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID-000003</th>\n",
       "      <td>NWIIsdP@hotmail.com</td>\n",
       "      <td>男</td>\n",
       "      <td>49.0</td>\n",
       "      <td>高中</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID-000004</th>\n",
       "      <td>lypSDjU@sina.com</td>\n",
       "      <td>女</td>\n",
       "      <td>27.0</td>\n",
       "      <td>研究生</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID-000005</th>\n",
       "      <td>ibvJneI@hotmail.com</td>\n",
       "      <td>男</td>\n",
       "      <td>24.0</td>\n",
       "      <td>研究生</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            邮箱 性别    年龄   学历\n",
       "ID                                          \n",
       "ID-000001       oZuSkKV@qq.com  男  38.0  研究生\n",
       "ID-000002    IWmJnPR@yahoo.com  女  37.0   高中\n",
       "ID-000003  NWIIsdP@hotmail.com  男  49.0   高中\n",
       "ID-000004     lypSDjU@sina.com  女  27.0  研究生\n",
       "ID-000005  ibvJneI@hotmail.com  男  24.0  研究生"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = pd.concat(\n",
    "    [\n",
    "        pd.read_csv(\n",
    "            \"data/ch6/employee/info_%s.csv\"%i\n",
    "        ).set_index(\"ID\")\n",
    "        for i in list(\"abc\")\n",
    "    ], axis=1\n",
    ")\n",
    "res = res.reindex([\"ID-%06d\"%(i) for i in range(1, 25001)])\n",
    "res = res[[\"邮箱\",\"性别\",\"年龄\",\"学历\"]]\n",
    "res.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57918c1d",
   "metadata": {},
   "source": [
    "- 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e61d7211",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>邮箱</th>\n",
       "      <th>性别</th>\n",
       "      <th>年龄</th>\n",
       "      <th>学历</th>\n",
       "      <th>2018-Q1</th>\n",
       "      <th>2018-Q2</th>\n",
       "      <th>2018-Q3</th>\n",
       "      <th>2018-Q4</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ID-000001</th>\n",
       "      <td>oZuSkKV@qq.com</td>\n",
       "      <td>男</td>\n",
       "      <td>38.0</td>\n",
       "      <td>研究生</td>\n",
       "      <td>37200</td>\n",
       "      <td>40100</td>\n",
       "      <td>50400</td>\n",
       "      <td>43900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID-000002</th>\n",
       "      <td>IWmJnPR@yahoo.com</td>\n",
       "      <td>女</td>\n",
       "      <td>37.0</td>\n",
       "      <td>高中</td>\n",
       "      <td>43400</td>\n",
       "      <td>40000</td>\n",
       "      <td>41900</td>\n",
       "      <td>44100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID-000003</th>\n",
       "      <td>NWIIsdP@hotmail.com</td>\n",
       "      <td>男</td>\n",
       "      <td>49.0</td>\n",
       "      <td>高中</td>\n",
       "      <td>27800</td>\n",
       "      <td>43700</td>\n",
       "      <td>21100</td>\n",
       "      <td>48300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID-000004</th>\n",
       "      <td>lypSDjU@sina.com</td>\n",
       "      <td>女</td>\n",
       "      <td>27.0</td>\n",
       "      <td>研究生</td>\n",
       "      <td>50900</td>\n",
       "      <td>33300</td>\n",
       "      <td>42700</td>\n",
       "      <td>49900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID-000005</th>\n",
       "      <td>ibvJneI@hotmail.com</td>\n",
       "      <td>男</td>\n",
       "      <td>24.0</td>\n",
       "      <td>研究生</td>\n",
       "      <td>44100</td>\n",
       "      <td>40300</td>\n",
       "      <td>29600</td>\n",
       "      <td>36800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            邮箱 性别    年龄   学历  2018-Q1  2018-Q2  2018-Q3  \\\n",
       "ID                                                                        \n",
       "ID-000001       oZuSkKV@qq.com  男  38.0  研究生    37200    40100    50400   \n",
       "ID-000002    IWmJnPR@yahoo.com  女  37.0   高中    43400    40000    41900   \n",
       "ID-000003  NWIIsdP@hotmail.com  男  49.0   高中    27800    43700    21100   \n",
       "ID-000004     lypSDjU@sina.com  女  27.0  研究生    50900    33300    42700   \n",
       "ID-000005  ibvJneI@hotmail.com  男  24.0  研究生    44100    40300    29600   \n",
       "\n",
       "           2018-Q4  \n",
       "ID                  \n",
       "ID-000001    43900  \n",
       "ID-000002    44100  \n",
       "ID-000003    48300  \n",
       "ID-000004    49900  \n",
       "ID-000005    36800  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.concat(\n",
    "    [\n",
    "        pd.read_csv(\n",
    "            \"data/ch6/employee/award/%d-%02d.csv\"%(y,m), index_col=\"ID\"\n",
    "        ) + pd.read_csv(\n",
    "            \"data/ch6/employee/salary/%d-%02d.csv\"%(y,m), index_col=\"ID\"\n",
    "        ) for y in range(2018,2021) for m in range(1,13)\n",
    "    ], axis=1\n",
    ")\n",
    "values = data.values.reshape(25000, -1, 3).sum(-1)\n",
    "res_values = pd.DataFrame(\n",
    "    values,\n",
    "    index=res.index,\n",
    "    columns=[\"%d-Q%d\"%(y,q) for y in range(2018,2021) for q in range(1,5)]\n",
    ")\n",
    "res = pd.concat([res, res_values], axis=1)\n",
    "res.iloc[:5, :8] # 展示部分"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbfb0802",
   "metadata": {},
   "source": [
    "## 二、实现join函数\n",
    "\n",
    "请按照如下要求实现join()函数：\n",
    "\n",
    "- 函数的调用方式为join(df1, df2, how, lsuffix, rsuffix)\n",
    "- 传入的df1和df2参数都为单级索引的DataFrame\n",
    "- how参数支持left、right、inner、outer和cross\n",
    "- 给出测试样例，并与pandas中join()的运行结果进行对比\n",
    "- 在实现过程中允许使用pd.concat()\n",
    "\n",
    "```{note}\n",
    "由于合并时可能产生缺失值，导致自定义join函数和pandas内置的join函数在列的dtype上会产生差别，此时使用equals()函数在这种情况下不能进行判定，可以使用pd.testing.assert_frame_equal(my_result, pandas_result, check_dtype=False)来进行对比。assert_frame_equal()通过check_dtype参数可以关闭列类型的检查，它在两个表存在差异时会报错，在两个表相同时不进行任何操作。\n",
    "```\n",
    "\n",
    "```text\n",
    "【解答】\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9e9d43c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def join(df1, df2, how, lsuffix=None, rsuffix=None):\n",
    "    idx1, idx2 = df1.columns, df2.columns\n",
    "    idx_intersect = idx1.intersection(idx2)\n",
    "    if len(idx_intersect) > 0:\n",
    "        if lsuffix==None or rsuffix==None:\n",
    "            raise ValueError(\n",
    "                \"columns overlap but get suffix not specified: \" \n",
    "                + str(idx_intersect))\n",
    "        df1 = df1.rename(columns={i:i+lsuffix for i in idx_intersect})\n",
    "        df2 = df2.rename(columns={i:i+rsuffix for i in idx_intersect})\n",
    "    idx1, idx2 = df1.index, df2.index\n",
    "    idx = idx1.union(idx2).unique().sort_values()\n",
    "    columns = pd.Index(df1.columns.tolist() + df2.columns.tolist())\n",
    "    res = pd.DataFrame(columns=columns, index=pd.Index([], name=idx1.name))\n",
    "    for x in idx:\n",
    "        _idx1, _idx2 = idx1 == x, idx2 == x\n",
    "        in1, in2 = bool(_idx1.sum()), bool(_idx2.sum())\n",
    "        if in1 and in2:\n",
    "            _df1, _df2 = df1.loc[[x]], df2.loc[[x]]\n",
    "            if how in [\"right\"]:\n",
    "                for i in range(_df2.shape[0]):\n",
    "                    _res = pd.concat([_df2.iloc[[i]]] * _df1.shape[0])\n",
    "                    _res = pd.concat([_df1, _res], axis=1)\n",
    "                    res = pd.concat([res, _res])\n",
    "            else:\n",
    "                for i in range(_df1.shape[0]):\n",
    "                    _res = pd.concat([_df1.iloc[[i]]] * _df2.shape[0])\n",
    "                    _res = pd.concat([_res, _df2], axis=1)\n",
    "                    res = pd.concat([res, _res])\n",
    "        elif not in1 and how in [\"right\", \"outer\"]:\n",
    "            _res = df2.loc[[x]].copy()\n",
    "            for c in df1.columns:\n",
    "                _res[c] = np.nan\n",
    "            res = pd.concat([res, _res.reindex(columns, axis=1)])\n",
    "        elif not in2 and how in [\"left\", \"outer\"]:\n",
    "            _res = df1.loc[[x]].copy()\n",
    "            for c in df2.columns:\n",
    "                _res[c] = np.nan\n",
    "            res = pd.concat([res, _res])\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8103fc2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_res_left = join(df1, df2, how=\"left\", lsuffix=\"_x\", rsuffix=\"_y\")\n",
    "my_res_right = join(df1, df2, how=\"right\", lsuffix=\"_x\", rsuffix=\"_y\")\n",
    "my_res_inner = join(df1, df2, how=\"inner\", lsuffix=\"_x\", rsuffix=\"_y\")\n",
    "my_res_outer = join(df1, df2, how=\"outer\", lsuffix=\"_x\", rsuffix=\"_y\")\n",
    "pd_res_left = df1.join(df2, lsuffix=\"_x\", rsuffix=\"_y\", how=\"left\")\n",
    "pd_res_right = df1.join(df2, lsuffix=\"_x\", rsuffix=\"_y\", how=\"right\")\n",
    "pd_res_inner = df1.join(df2, lsuffix=\"_x\", rsuffix=\"_y\", how=\"inner\")\n",
    "pd_res_outer = df1.join(df2, lsuffix=\"_x\", rsuffix=\"_y\", how=\"outer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8a6aabbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.testing import assert_frame_equal\n",
    "assert_frame_equal(my_res_left, pd_res_left, check_dtype=False)\n",
    "assert_frame_equal(my_res_right, pd_res_right, check_dtype=False)\n",
    "assert_frame_equal(my_res_inner, pd_res_inner, check_dtype=False)\n",
    "assert_frame_equal(my_res_outer, pd_res_outer, check_dtype=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5f20155",
   "metadata": {},
   "source": [
    "## 三、条件连接\n",
    "\n",
    "在本章介绍的关系型连接中，merge()、join()和concat()都是等值连接，即每一个左表键中的label只会与右表键中完全相同的label进行笛卡尔积的匹配。现在，我们希望左表中的键只要与右表中的键满足一定条件就进行匹配，下面给出一种根据大小关系匹配的例子。\n",
    "\n",
    "假设df1和df2的构造如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "596d407b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Key</th>\n",
       "      <th>Col1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Key  Col1\n",
       "0    0    10\n",
       "1    1    20\n",
       "2    1    30\n",
       "3    2    40"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = pd.DataFrame({\"Key\":[0,1,1,2], \"Col1\":[10,20,30,40]})\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b9ef622d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Key</th>\n",
       "      <th>Col2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Key  Col2\n",
       "0    1    50\n",
       "1    1    60\n",
       "2    2    70\n",
       "3    3    80"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = pd.DataFrame({\"Key\":[1,1,2,3], \"Col2\":[50,60,70,80]})\n",
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fa6b3a2",
   "metadata": {},
   "source": [
    "我们希望通过conditional_merge()函数对df1和df2进行左连接，连接规则是左键元素值不得小于右键元素值，即conditional_merge(df1, df2, on=\"Key\", how=\"left\", rule=\"x>=y\")的期望结果如下所示："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "10e0a460",
   "metadata": {
    "tags": [
     "remove_input"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Key_x</th>\n",
       "      <th>Col1</th>\n",
       "      <th>Key_y</th>\n",
       "      <th>Col2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>1.0</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>1.0</td>\n",
       "      <td>60.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>1.0</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>1.0</td>\n",
       "      <td>60.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>40</td>\n",
       "      <td>1.0</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2</td>\n",
       "      <td>40</td>\n",
       "      <td>1.0</td>\n",
       "      <td>60.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>40</td>\n",
       "      <td>2.0</td>\n",
       "      <td>70.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Key_x  Col1  Key_y  Col2\n",
       "0      0    10    NaN   NaN\n",
       "1      1    20    1.0  50.0\n",
       "2      1    20    1.0  60.0\n",
       "3      1    30    1.0  50.0\n",
       "4      1    30    1.0  60.0\n",
       "5      2    40    1.0  50.0\n",
       "6      2    40    1.0  60.0\n",
       "7      2    40    2.0  70.0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(\n",
    "    {\n",
    "        \"Key_x\": [0,1,1,1,1,2,2,2],\n",
    "        \"Col1\": [10,20,20,30,30,40,40,40],\n",
    "        \"Key_y\": [np.nan,1,1,1,1,1,1,2],\n",
    "        \"Col2\": [np.nan,50,60,50,60,50,60,70]\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8399b82",
   "metadata": {},
   "source": [
    "- 实现上述根据大小关系连接的conditional_merge()函数，其中rule参数可取\"x>=y\"、\"x>y\"、\"x==y\"、\"x!=y\"、\"x<=y\"和\"x<y\"。此处仅实现左连接版本即可，即无需考虑how参数。\n",
    "- 在data/ch6/left.csv和data/ch6/right.csv中分别存放了两张表，我们希望对两张表以经纬度（Longitude和Latitude）为键进行条件连接，连接规则是左键元素值和右键元素值的球面距离不得超过$d$千米，请实现这个连接函数spherical_merge(df1, df2, distance=d, on=[\"Longitude\", \"Latitude\"])。此处由于左键和右键均无重复值，故无需考虑连接方式。球面距离的计算可以通过sklearn库的haversine_distances()函数实现，其安装方式为conda install scikit-learn，使用方法如代码所示。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "13faf634",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 655.96280506, 1449.73574186,  276.84030423,  802.01737182,\n",
       "         540.95925895],\n",
       "       [1272.59889369,  387.16558823, 1358.01183355, 1582.95966523,\n",
       "        1069.38156885],\n",
       "       [ 669.35082711,  467.07489446,  742.49209123, 1002.65697447,\n",
       "         458.35353128],\n",
       "       [1104.42662432,  146.24538034, 1254.17621209, 1393.16408848,\n",
       "         973.28985989],\n",
       "       [ 388.63154244,  754.15164741,  427.75601403,  735.42275194,\n",
       "         172.40958435]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import haversine_distances\n",
    "df1 = pd.read_csv(\"data/ch6/left.csv\").head()\n",
    "df2 = pd.read_csv(\"data/ch6/right.csv\").head()\n",
    "def get_distance(df1, df2):\n",
    "    rad1 = np.stack([np.radians(df1.Latitude), np.radians(df1.Longitude)], axis=-1)\n",
    "    rad2 = np.stack([np.radians(df2.Latitude), np.radians(df2.Longitude)], axis=-1)\n",
    "    result = haversine_distances(rad1, rad2) * 6371000 / 1000 # 乘以地球半径并转为km\n",
    "    return result\n",
    "get_distance(df1, df2) # 第i行第j列代表df1的第i个点到df2的第j个点的球面距离"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71029144",
   "metadata": {},
   "source": [
    "```text\n",
    "【解答】\n",
    "```\n",
    "\n",
    "- 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d24e1b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.DataFrame({\"Key\":[0,1,1,2], \"Col1\":[10,20,30,40]})\n",
    "df2 = pd.DataFrame({\"Key\":[1,1,2,3], \"Col2\":[50,60,70,80]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0711bbb0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Key_x</th>\n",
       "      <th>Col1</th>\n",
       "      <th>Key_y</th>\n",
       "      <th>Col2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>1.0</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>1.0</td>\n",
       "      <td>60.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>1.0</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>1.0</td>\n",
       "      <td>60.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>40</td>\n",
       "      <td>1.0</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2</td>\n",
       "      <td>40</td>\n",
       "      <td>1.0</td>\n",
       "      <td>60.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>40</td>\n",
       "      <td>2.0</td>\n",
       "      <td>70.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Key_x  Col1  Key_y  Col2\n",
       "0      0    10    NaN   NaN\n",
       "1      1    20    1.0  50.0\n",
       "2      1    20    1.0  60.0\n",
       "3      1    30    1.0  50.0\n",
       "4      1    30    1.0  60.0\n",
       "5      2    40    1.0  50.0\n",
       "6      2    40    1.0  60.0\n",
       "7      2    40    2.0  70.0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rule_helper = lambda rule: lambda x, y: eval(rule)\n",
    "def conditional_merge(df1, df2, on, rule):\n",
    "    grouper = df1.groupby(on)\n",
    "    rule_func = rule_helper(rule)\n",
    "    def merge_helper(_df1):\n",
    "        left_key = _df1[on].iloc[0]\n",
    "        right_key = df2[on]\n",
    "        _df2 = df2[rule_func(left_key, right_key)]\n",
    "        if _df2.shape[0] == 0:\n",
    "            _df1 = _df1.rename(columns={on: on+\"_x\"})\n",
    "            _df2 = _df2.rename(columns={on: on+\"_y\"})\n",
    "            return pd.concat([_df1, _df2], axis=1)\n",
    "        else:\n",
    "            return _df1.merge(_df2, how=\"cross\")\n",
    "    return grouper.apply(merge_helper).reset_index(drop=True)\n",
    "conditional_merge(df1, df2, \"Key\", \"x>=y\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ee8f311",
   "metadata": {},
   "source": [
    "- 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f2ad9996",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Longitude_x</th>\n",
       "      <th>Latitude_x</th>\n",
       "      <th>Col1</th>\n",
       "      <th>Longitude_y</th>\n",
       "      <th>Latitude_y</th>\n",
       "      <th>Col2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>121.102062</td>\n",
       "      <td>30.216142</td>\n",
       "      <td>0</td>\n",
       "      <td>121.243898</td>\n",
       "      <td>30.353029</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>115.885544</td>\n",
       "      <td>36.079370</td>\n",
       "      <td>0</td>\n",
       "      <td>115.947204</td>\n",
       "      <td>35.922811</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>113.791836</td>\n",
       "      <td>36.724240</td>\n",
       "      <td>9</td>\n",
       "      <td>113.709950</td>\n",
       "      <td>36.608670</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>128.633906</td>\n",
       "      <td>39.729151</td>\n",
       "      <td>1</td>\n",
       "      <td>128.536029</td>\n",
       "      <td>39.631795</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>128.633906</td>\n",
       "      <td>39.729151</td>\n",
       "      <td>1</td>\n",
       "      <td>128.636761</td>\n",
       "      <td>39.898670</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Longitude_x  Latitude_x  Col1  Longitude_y  Latitude_y  Col2\n",
       "0   121.102062   30.216142     0   121.243898   30.353029     7\n",
       "1   115.885544   36.079370     0   115.947204   35.922811     2\n",
       "2   113.791836   36.724240     9   113.709950   36.608670     4\n",
       "3   128.633906   39.729151     1   128.536029   39.631795     2\n",
       "4   128.633906   39.729151     1   128.636761   39.898670     5"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = pd.read_csv(\"data/ch6/left.csv\")\n",
    "df2 = pd.read_csv(\"data/ch6/right.csv\")\n",
    "\n",
    "def spherical_merge(df1, df2, d=200, on=[\"Longitude\", \"Latitude\"]):\n",
    "    if on[0] not in df1.columns or on[0] not in df2.columns:\n",
    "        raise ValueError(\"Longitude not in df1's columns or df2's columns.\")\n",
    "    if on[1] not in df1.columns or on[1] not in df2.columns:\n",
    "        raise ValueError(\"Latitude not in df1's columns or df2's columns.\")\n",
    "    distance = get_distance(df1, df2)\n",
    "    res = pd.concat(\n",
    "        [\n",
    "            df1.iloc[[i]].merge(df2.loc[distance[i] <= d], how=\"cross\")\n",
    "            for i in range(df1.shape[0])\n",
    "        ]\n",
    "    )\n",
    "    return res.reset_index(drop=True)\n",
    "\n",
    "res = spherical_merge(df1, df2, 30)\n",
    "res.head()"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "text_representation": {
    "format_name": "myst"
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "source_map": [
   10,
   19,
   48,
   53,
   58,
   61,
   67,
   88,
   98,
   103,
   105,
   109,
   111,
   126,
   138,
   142,
   160,
   181,
   224,
   235,
   241,
   250,
   255,
   258,
   262,
   273,
   280,
   290,
   298,
   303,
   320,
   324
  ]
 },
 "nbformat": 4,
 "nbformat_minor": 5
}